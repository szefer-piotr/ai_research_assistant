{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "# If you want to chunk PDF text, you can also import TextSplitter utilities:\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import PyPDF2\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configure OpenAI Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY= os.getenv('OPENAI_API_KEY')\n",
    "# In code, you might do:\n",
    "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract all text from a PDF file using PyPDF2.\n",
    "    \"\"\"\n",
    "    text_content = []\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        for page in reader.pages:\n",
    "            text_content.append(page.extract_text())\n",
    "    return \"\\n\".join(text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def summarize_excel_to_json(file_path):\n",
    "    \"\"\"\n",
    "    Reads an Excel (.xlsx) file and creates a JSON summary of each sheet.\n",
    "    For each column it provides:\n",
    "      1. The variable (column) name.\n",
    "      2. The inferred variable type (numeric, datetime, categorical).\n",
    "      3. For numeric columns: standard summary statistics.\n",
    "      4. For categorical columns: unique values and their counts.\n",
    "      5. For datetime columns: the time span (min and max dates).\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): The path to the Excel file.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON string summarizing the workbook.\n",
    "    \"\"\"\n",
    "    workbook_summary = {}\n",
    "    # Load the Excel file\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "\n",
    "    # Process each sheet in the workbook\n",
    "    for sheet in xls.sheet_names:\n",
    "        df = pd.read_excel(xls, sheet_name=sheet)\n",
    "        sheet_summary = []\n",
    "        \n",
    "        # Process each column in the sheet\n",
    "        for col in df.columns:\n",
    "            column_summary = {\"variable_name\": str(col)}\n",
    "            series = df[col]\n",
    "\n",
    "            # Infer the variable type: numeric, datetime, or categorical\n",
    "            if pd.api.types.is_numeric_dtype(series):\n",
    "                column_summary[\"variable_type\"] = \"numeric\"\n",
    "                # Compute summary statistics\n",
    "                stats = series.describe()\n",
    "                column_summary[\"summary_statistics\"] = {\n",
    "                    \"count\": stats.get(\"count\"),\n",
    "                    \"mean\": stats.get(\"mean\"),\n",
    "                    \"std\": stats.get(\"std\"),\n",
    "                    \"min\": stats.get(\"min\"),\n",
    "                    \"25%\": stats.get(\"25%\"),\n",
    "                    \"50%\": stats.get(\"50%\"),\n",
    "                    \"75%\": stats.get(\"75%\"),\n",
    "                    \"max\": stats.get(\"max\")\n",
    "                }\n",
    "            elif pd.api.types.is_datetime64_any_dtype(series):\n",
    "                column_summary[\"variable_type\"] = \"datetime\"\n",
    "                # Compute time span (min and max)\n",
    "                times = series.dropna()\n",
    "                if not times.empty:\n",
    "                    column_summary[\"time_span\"] = {\n",
    "                        \"start\": str(times.min()),\n",
    "                        \"end\": str(times.max())\n",
    "                    }\n",
    "                else:\n",
    "                    column_summary[\"time_span\"] = {\"start\": None, \"end\": None}\n",
    "            else:\n",
    "                column_summary[\"variable_type\"] = \"categorical\"\n",
    "                # Compute unique values and their counts\n",
    "                uniques = series.value_counts(dropna=False)\n",
    "                unique_values = []\n",
    "                for value, count in uniques.items():\n",
    "                    # Represent NaN values as the string \"NaN\"\n",
    "                    value_str = \"NaN\" if pd.isna(value) else str(value)\n",
    "                    unique_values.append({\"value\": value_str, \"count\": int(count)})\n",
    "                column_summary[\"unique_values\"] = unique_values\n",
    "\n",
    "            sheet_summary.append(column_summary)\n",
    "        workbook_summary[sheet] = sheet_summary\n",
    "\n",
    "    # Convert the dictionary to a formatted JSON string\n",
    "    json_str = json.dumps(workbook_summary, indent=2)\n",
    "    return json_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx_path = \"../data/poc_example_data/lazaro_et_al_2021.xlsx\"\n",
    "dataset_summary = summarize_excel_to_json(xlsx_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LangChain LLM Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization_llm = ChatOpenAI(\n",
    "    temperature=0.0,\n",
    "    model_name=\"gpt-4o\" \n",
    ")\n",
    "\n",
    "planner_llm = ChatOpenAI(\n",
    "    model_name=\"o1-mini\"\n",
    ")\n",
    "\n",
    "executor_llm = ChatOpenAI(\n",
    "    model_name=\"o1-mini\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_summary_prompt = PromptTemplate(\n",
    "    input_variables=[\"full_text\"],\n",
    "    template=(\n",
    "        \"You are a model specialized in ecological data analysis.\\n\"\n",
    "        \"Read the following text delimited by triple backticks and list all information on the dataset and statistical analyses used.\\n\"\n",
    "        \"Focus ONLY on:\\n\"\n",
    "        \"- Extracting all of the tested hypotheses.\\n\"\n",
    "        \"- Listing all variables that were collected.\\n\"\n",
    "        \"- Providing example values for categorical variables, and ranges for continuous variables (if available).\\n\"\n",
    "        \"- Listing all statistical methods with every detail of the performed analysis (specifically which functions, settings, and variables were used).\\n\"\n",
    "        \"Return only the report.\\n\"\n",
    "        \"```\\n{full_text}\\n```\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "planner_prompt = PromptTemplate(\n",
    "    input_variables=[\"methodology_summary\", \"dataset_summary\"],\n",
    "    template=(\n",
    "        \"You are a planning model. Based on the methodology summary and dataset summary, \"\n",
    "        \"plan a step-by-step routine (as programmatic pseudocode or structured steps) \"\n",
    "        \"to execute the identified statistical analyses on the full dataset.\\n\"\n",
    "        \"Think how each analysis helps to answer indyvidual hypotheses.\\n\\n\"\n",
    "        \"Methodology Summary:\\n{methodology_summary}\\n\\n\"\n",
    "        \"Dataset Summary:\\n{dataset_summary}\\n\\n\"\n",
    "        \"Provide your plan in XML format, with each <Step> containing a structured explanation \"\n",
    "        \"of how to implement it programmatically, and which hypothesis it addresses.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "executor_prompt = PromptTemplate(\n",
    "    input_variables=[\"analysis_plan_xml\", \"dataset_summary\"],\n",
    "    template=(\n",
    "        \"You are an executor model specialized in generating R scripts for each step. \"\n",
    "        \"Given the plan in XML, do the following:\\n\"\n",
    "        \"1. Generate separate R scripts for each analysis step.\\n\"\n",
    "        \"1.1. Use variable names from the data summary.\\n\"\n",
    "        \"1.2. Check whether an analysis is suitable for the variable types.\\n\"\n",
    "        \"1.3. Provide suggestions in comments on alternativees analyses.\\n\"\n",
    "        \"2. Generate a single master R script that runs them all in a structured manner.\\n\"\n",
    "        \"Output your results clearly, indicating how the scripts should be saved.\\n\\n\"\n",
    "        \"Plan XML:\\n{analysis_plan_xml}.\\n\"\n",
    "        \"Dataset summary:: \\n{dataset_summary}.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Read PDF and extract methodology ---\n",
    "pdf_path = \"../data/poc_example_data/lazaro_et_al_2021_accessible.pdf\"\n",
    "full_text = extract_text_from_pdf(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = methods_summary_prompt | summarization_llm\n",
    "methods_summary_result = chain.invoke({\"full_text\": full_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plan statistical analyses based on the methodology summary and the dataset summary\n",
    "planner_chain = planner_prompt | planner_llm\n",
    "plan_analyses_xml = planner_chain.invoke({\n",
    "    \"methodology_summary\": methods_summary_result,\n",
    "    \"dataset_summary\": dataset_summary\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='```xml\\n<AnalysisPlan>\\n    <Step number=\"1\">\\n        <Description>Load Required Libraries</Description>\\n        <Details>\\n            <Instruction>Ensure all necessary R packages are installed and loaded. This includes packages for statistical modeling, data manipulation, and network analysis.</Instruction>\\n            <Code>\\n                <![CDATA[\\n                # Install packages if not already installed\\n                required_packages <- c(\"lme4\", \"MuMIn\", \"car\", \"r2glmm\", \"piecewiseSEM\", \\n                                       \"bipartite\", \"dplyr\", \"tidyr\", \"emmeans\", \"corrr\")\\n                installed_packages <- rownames(installed.packages())\\n                for(pkg in required_packages){\\n                    if(!pkg %in% installed_packages){\\n                        install.packages(pkg)\\n                    }\\n                }\\n\\n                # Load libraries\\n                library(lme4)\\n                library(MuMIn)\\n                library(car)\\n                library(r2glmm)\\n                library(piecewiseSEM)\\n                library(bipartite)\\n                library(dplyr)\\n                library(tidyr)\\n                library(emmeans)\\n                library(corrr)\\n                ]]>\\n            </Code>\\n        </Details>\\n    </Step>\\n\\n    <Step number=\"2\">\\n        <Description>Import and Inspect Dataset</Description>\\n        <Details>\\n            <Instruction>Load the dataset into R and perform initial inspections to understand its structure and identify any missing or inconsistent data.</Instruction>\\n            <Code>\\n                <![CDATA[\\n                # Replace \\'your_dataset.csv\\' with the actual file name and path\\n                wild_bee_data <- read.csv(\"your_dataset.csv\", stringsAsFactors = TRUE)\\n\\n                # View the first few rows\\n                head(wild_bee_data)\\n\\n                # Summary statistics\\n                summary(wild_bee_data)\\n\\n                # Check for missing values\\n                sapply(wild_bee_data, function(x) sum(is.na(x)))\\n                ]]>\\n            </Code>\\n        </Details>\\n    </Step>\\n\\n    <Step number=\"3\">\\n        <Description>Data Preprocessing</Description>\\n        <Details>\\n            <Instruction>\\n                Prepare the data for analysis by handling missing values, encoding categorical variables, and scaling numerical variables as required.\\n            </Instruction>\\n            <SubSteps>\\n                <SubStep>\\n                    <Description>Handle Missing Values</Description>\\n                    <Details>\\n                        <Instruction>Decide on a strategy to handle missing data, such as imputation or removal of incomplete cases.</Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Example: Remove rows with missing values\\n                            wild_bee_data <- na.omit(wild_bee_data)\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Encode Categorical Variables</Description>\\n                    <Details>\\n                        <Instruction>Ensure that categorical variables are properly encoded as factors.</Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Convert categorical variables to factors\\n                            categorical_vars <- c(\"Island\", \"Island_Site\", \"family\", \"InsectSpecies\", \\n                                                  \"Apis\")\\n                            wild_bee_data[categorical_vars] <- lapply(wild_bee_data[categorical_vars], as.factor)\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Scale Numerical Variables</Description>\\n                    <Details>\\n                        <Instruction>Scale numerical variables as needed, especially for models that are sensitive to variable scaling.</Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Example: Scale numerical predictors\\n                            numeric_vars <- c(\"NumberHivesMinistry2005_2015\", \"HiveDensityMinistry2005-2015\",\\n                                              \"HiveDensityMinistry_STUDYYEAR\", \"NumberApis\", \"FlowerAbundance\",\\n                                              \"FlowerRichness\", \"LandscapeHeterogeneity\", \"Areakm2\",\\n                                              \"%NaturalHabitats\")\\n                            wild_bee_data[numeric_vars] <- scale(wild_bee_data[numeric_vars])\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n            </SubSteps>\\n        </Details>\\n    </Step>\\n\\n    <Step number=\"4\">\\n        <Description>Generalized Linear Mixed Models (GLMMs)</Description>\\n        <Details>\\n            <Instruction>Analyze the relationship between honey bee visitation rate and wild bee abundance and richness using GLMMs.</Instruction>\\n            <SubSteps>\\n                <SubStep>\\n                    <Description>Model Wild Bee Abundance</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Fit a GLMM for wild bee abundance with honey bee visitation rate and other predictors. Include \\'Island\\' as a random effect and use a Gamma distribution with a log link function.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Wild Bee Abundance Model\\n                            abundance_model <- glmer(WildBeeAbundanceSt ~ NumberApis + FlowerAbundance + FlowerRichness + \\n                                                     LandscapeHeterogeneity + log(Areakm2) + \\n                                                     (1 | Island), \\n                                                     data = wild_bee_data, \\n                                                     family = Gamma(link = \"log\"))\\n                            summary(abundance_model)\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Model Wild Bee Richness</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Fit a GLMM for wild bee richness using the same predictors and random effect as above.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Wild Bee Richness Model\\n                            richness_model <- glmer(WildBeeRichnessSt ~ NumberApis + FlowerAbundance + FlowerRichness + \\n                                                    LandscapeHeterogeneity + log(Areakm2) + \\n                                                    (1 | Island), \\n                                                    data = wild_bee_data, \\n                                                    family = Gamma(link = \"log\"))\\n                            summary(richness_model)\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Model Selection with Dredge</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Perform model selection using the dredge function to identify the best models with up to 4 predictors.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Set global options for MuMIn\\n                            options(na.action = \"na.fail\")\\n\\n                            # Model selection for abundance\\n                            abundance_dredge <- dredge(abundance_model, m.lim = c(0,4))\\n                            print(abundance_dredge)\\n\\n                            # Select the best model\\n                            best_abundance_model <- get.models(abundance_dredge, subset = 1)[[1]]\\n                            summary(best_abundance_model)\\n\\n                            # Model selection for richness\\n                            richness_dredge <- dredge(richness_model, m.lim = c(0,4))\\n                            print(richness_dredge)\\n\\n                            # Select the best model\\n                            best_richness_model <- get.models(richness_dredge, subset = 1)[[1]]\\n                            summary(best_richness_model)\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Assess Model Significance and R²</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Use likelihood ratio tests and calculate R² values to assess model performance.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Likelihood Ratio Tests\\n                            Anova(best_abundance_model, test = \"LRT\")\\n                            Anova(best_richness_model, test = \"LRT\")\\n\\n                            # Calculate R²\\n                            r2beta(best_abundance_model, method = \"nsjmin\", partial = TRUE)\\n                            r2beta(best_richness_model, method = \"nsjmin\", partial = TRUE)\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n            </SubSteps>\\n        </Details>\\n    </Step>\\n\\n    <Step number=\"5\">\\n        <Description>Variation Inflation Factor (VIF) Analysis</Description>\\n        <Details>\\n            <Instruction>Identify and address multicollinearity among landscape variables using VIF.</Instruction>\\n            <Code>\\n                <![CDATA[\\n                # Calculate VIF for the best abundance model\\n                vif(best_abundance_model)\\n\\n                # Calculate VIF for the best richness model\\n                vif(best_richness_model)\\n\\n                # If VIF > 5 or 10, consider removing or combining variables\\n                ]]>\\n            </Code>\\n        </Details>\\n    </Step>\\n\\n    <Step number=\"6\">\\n        <Description>Piecewise Structural Equation Modeling (SEM)</Description>\\n        <Details>\\n            <Instruction>\\n                Summarize direct and indirect effects of honey bee visitation rate on wild bee network metrics using Piecewise SEM.\\n            </Instruction>\\n            <SubSteps>\\n                <SubStep>\\n                    <Description>Scale Variables</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Scale the necessary variables before fitting the SEM.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            wild_bee_data_scaled <- wild_bee_data %>%\\n                                mutate_at(vars(NumberApis, FlowerAbundance, FlowerRichness, \\n                                               LandscapeHeterogeneity, Areakm2, \\n                                               WildBeeAbundanceSt, WildBeeRichnessSt), scale)\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Define SEM Model</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Specify the relationships between variables as per the hypotheses.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            sem_model <- psem(\\n                                glmer(WildBeeAbundanceSt ~ NumberApis + FlowerAbundance + FlowerRichness + \\n                                      LandscapeHeterogeneity + log(Areakm2) + \\n                                      (1 | Island), \\n                                      data = wild_bee_data_scaled, \\n                                      family = Gamma(link = \"log\")),\\n                                glmer(WildBeeRichnessSt ~ NumberApis + FlowerAbundance + FlowerRichness + \\n                                      LandscapeHeterogeneity + log(Areakm2) + \\n                                      (1 | Island), \\n                                      data = wild_bee_data_scaled, \\n                                      family = Gamma(link = \"log\")),\\n                                log(Areakm2) ~ NumberApis + FlowerAbundance + \\n                                    FlowerRichness + LandscapeHeterogeneity,\\n                                NumberApis ~ FlowerAbundance + FlowerRichness + LandscapeHeterogeneity\\n                            )\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Fit SEM Model and Assess Fit</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Fit the SEM model and evaluate its goodness-of-fit using directed separation tests.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Fit the SEM model\\n                            sem_fit <- sem.fit(sem_model, data = wild_bee_data_scaled)\\n                            summary(sem_fit, standardize = TRUE, fit.measures = TRUE)\\n\\n                            # Goodness-of-fit tests\\n                            sem.fit(sem_model, data = wild_bee_data_scaled, test = \"standard\")\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n            </SubSteps>\\n        </Details>\\n    </Step>\\n\\n    <Step number=\"7\">\\n        <Description>Pollination Network Analysis</Description>\\n        <Details>\\n            <Instruction>\\n                Construct and analyze pollination networks using the bipartite package.\\n            </Instruction>\\n            <SubSteps>\\n                <SubStep>\\n                    <Description>Construct Bipartite Networks</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Use hand-netting data to create bipartite matrices representing plant-pollinator interactions.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Assuming \\'pollination_data\\' is a separate dataframe with Plant and Pollinator interactions\\n                            # Replace with actual data loading if different\\n                            pollination_data <- read.csv(\"pollination_network.csv\", stringsAsFactors = TRUE)\\n\\n                            # Create a bipartite matrix\\n                            bipartite_matrix <- with(pollination_data, table(PlantSpecies, PollinatorSpecies))\\n\\n                            # Convert to matrix\\n                            bipartite_matrix <- as.matrix(bipartite_matrix)\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Calculate Network Indices</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Calculate various network metrics such as number of links, linkage density, nestedness, and modularity.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Number of links\\n                            num_links <- networklevel(bipartite_matrix, index = \"links\")\\n\\n                            # Number of plant species\\n                            num_plants <- networklevel(bipartite_matrix, index = \"species.level\")\\n\\n                            # Linkage density\\n                            linkage_density <- linkage(bipartite_matrix)\\n\\n                            # Nestedness\\n                            nestedness <- networklevel(bipartite_matrix, index = \"weighted NODF\")\\n\\n                            # Modularity\\n                            modularity <- networklevel(bipartite_matrix, index = \"module\")\\n\\n                            # Combine indices into a dataframe\\n                            network_indices <- data.frame(\\n                                NumberOfLinks = num_links,\\n                                NumberOfPlantSpecies = num_plants,\\n                                LinkageDensity = linkage_density,\\n                                Nestedness = nestedness,\\n                                Modularity = modularity\\n                            )\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Assess Against Null Models</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Compare observed network metrics against null models using the vaznull null model for z-scores.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Calculate z-scores using vaznull null model\\n                            z_linkage_density <- nullmodel(bipartite_matrix, method = \"vaznull\")$zLinkage\\n                            z_nestedness <- nullmodel(bipartite_matrix, method = \"vaznull\")$zNODF\\n                            z_modularity <- nullmodel(bipartite_matrix, method = \"vaznull\")$zModularity\\n\\n                            # Add z-scores to network_indices\\n                            network_indices$Z_LinkageDensity <- z_linkage_density\\n                            network_indices$Z_Nestedness <- z_nestedness\\n                            network_indices$Z_Modularity <- z_modularity\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n            </SubSteps>\\n        </Details>\\n    </Step>\\n\\n    <Step number=\"8\">\\n        <Description>Potential Competition Analysis</Description>\\n        <Details>\\n            <Instruction>\\n                Measure species niche overlap using the Apparent Competition Index as per Müller et al. (1999).\\n            </Instruction>\\n            <SubSteps>\\n                <SubStep>\\n                    <Description>Prepare Species Interaction Matrix</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Transpose the species interaction matrix to align species appropriately for PAC calculation.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Transpose the bipartite matrix\\n                            transposed_matrix <- t(bipartite_matrix)\\n\\n                            # Ensure the matrix is binary (presence/absence)\\n                            transposed_matrix[transposed_matrix > 0] <- 1\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Calculate Apparent Competition Index</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Use the PAC function to compute the niche overlap among species.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Using PAC function (assuming PAC is defined or use a suitable package)\\n                            # If PAC function is not available, consider using niche overlap functions from other packages\\n\\n                            # Example using nicheOverlap from vegan\\n                            if(!\"vegan\" %in% installed.packages()){\\n                                install.packages(\"vegan\")\\n                            }\\n                            library(vegan)\\n\\n                            # Calculate niche overlap using Pianka\\'s index\\n                            niche_overlap <- nicheOverlap(transposed_matrix, method = \"Pianka\")\\n\\n                            # Convert to Apparent Competition Index if specific formula is needed\\n                            # Placeholder as PAC formula is specific\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n            </SubSteps>\\n        </Details>\\n    </Step>\\n\\n    <Step number=\"9\">\\n        <Description>A Posteriori Tests for Differences Between Slopes</Description>\\n        <Details>\\n            <Instruction>\\n                Perform post-hoc tests to examine differences between slopes for each wild bee family using the emtrends function from the emmeans package.\\n            </Instruction>\\n            <SubSteps>\\n                <SubStep>\\n                    <Description>Fit Interaction Models</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Include interaction terms between honey bee visitation rate and bee family in the GLMMs.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Interaction model for abundance\\n                            interaction_model_abundance <- glmer(WildBeeAbundanceSt ~ NumberApis * family + FlowerAbundance + \\n                                                                 FlowerRichness + LandscapeHeterogeneity + log(Areakm2) + \\n                                                                 (1 | Island), \\n                                                                 data = wild_bee_data, \\n                                                                 family = Gamma(link = \"log\"))\\n                            \\n                            # Interaction model for richness\\n                            interaction_model_richness <- glmer(WildBeeRichnessSt ~ NumberApis * family + FlowerAbundance + \\n                                                                FlowerRichness + LandscapeHeterogeneity + log(Areakm2) + \\n                                                                (1 | Island), \\n                                                                data = wild_bee_data, \\n                                                                family = Gamma(link = \"log\"))\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Perform Emtrends Analysis</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Use emtrends to estimate and compare the slopes of honey bee visitation rate across different bee families.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Emtrends for abundance\\n                            emtrends_abundance <- emtrends(interaction_model_abundance, \\n                                                          pairwise ~ family, \\n                                                          var = \"NumberApis\")\\n                            summary(emtrends_abundance)\\n\\n                            # Emtrends for richness\\n                            emtrends_richness <- emtrends(interaction_model_richness, \\n                                                         pairwise ~ family, \\n                                                         var = \"NumberApis\")\\n                            summary(emtrends_richness)\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n            </SubSteps>\\n        </Details>\\n    </Step>\\n\\n    <Step number=\"10\">\\n        <Description>Export and Document Results</Description>\\n        <Details>\\n            <Instruction>\\n                Save all model outputs, summaries, and important statistics to files for reporting and further analysis.\\n            </Instruction>\\n            <SubSteps>\\n                <SubStep>\\n                    <Description>Save Model Summaries</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Export summaries of GLMMs, SEMs, and other analyses to text or PDF files.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Save GLMM summaries\\n                            sink(\"GLMM_Abundance_Summary.txt\")\\n                            summary(best_abundance_model)\\n                            sink()\\n\\n                            sink(\"GLMM_Richness_Summary.txt\")\\n                            summary(best_richness_model)\\n                            sink()\\n\\n                            # Save SEM summary\\n                            sink(\"SEM_Summary.txt\")\\n                            summary(sem_fit, standardize = TRUE, fit.measures = TRUE)\\n                            sink()\\n\\n                            # Save Emtrends summaries\\n                            sink(\"Emtrends_Abundance_Summary.txt\")\\n                            summary(emtrends_abundance)\\n                            sink()\\n\\n                            sink(\"Emtrends_Richness_Summary.txt\")\\n                            summary(emtrends_richness)\\n                            sink()\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Save Network Indices</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Export the calculated network indices to a CSV file for reporting.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            write.csv(network_indices, \"Pollination_Network_Indices.csv\", row.names = FALSE)\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Save PAC Results</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Export the Apparent Competition Index results to a CSV file.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            write.csv(niche_overlap, \"Apparent_Competition_Index.csv\", row.names = TRUE)\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n            </SubSteps>\\n        </Details>\\n    </Step>\\n\\n    <Step number=\"11\">\\n        <Description>Visualization of Results</Description>\\n        <Details>\\n            <Instruction>\\n                Create visualizations to illustrate the findings from the statistical analyses, such as effect plots, network diagrams, and VIF plots.\\n            </Instruction>\\n            <SubSteps>\\n                <SubStep>\\n                    <Description>Effect Plots for GLMMs</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Use the emmeans package to plot estimated marginal means and trends.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Plot for abundance\\n                            plot(emtrends_abundance, comparisons = TRUE) +\\n                                ggtitle(\"Effect of NumberApis on Wild Bee Abundance by Family\")\\n\\n                            # Plot for richness\\n                            plot(emtrends_richness, comparisons = TRUE) +\\n                                ggtitle(\"Effect of NumberApis on Wild Bee Richness by Family\")\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Network Diagrams</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Visualize the pollination networks using the bipartite package.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Basic network plot\\n                            plotweb(bipartite_matrix, method = \"normal\", \\n                                    title = \"Pollination Network\", \\n                                    text.rot = 90, text.spacing = 0.5)\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>VIF Plot</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Visualize VIF values to assess multicollinearity.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Calculate VIF and plot\\n                            vif_values <- vif(best_abundance_model)\\n                            vif_df <- data.frame(Variable = names(vif_values), VIF = vif_values)\\n\\n                            library(ggplot2)\\n                            ggplot(vif_df, aes(x = reorder(Variable, VIF), y = VIF)) +\\n                                geom_bar(stat = \"identity\", fill = \"steelblue\") +\\n                                coord_flip() +\\n                                geom_hline(yintercept = 5, linetype = \"dashed\", color = \"red\") +\\n                                labs(title = \"VIF Values for Predictors\",\\n                                     x = \"Variables\",\\n                                     y = \"VIF\") +\\n                                theme_minimal()\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n            </SubSteps>\\n        </Details>\\n    </Step>\\n\\n    <Step number=\"12\">\\n        <Description>Report Findings</Description>\\n        <Details>\\n            <Instruction>\\n                Compile all results, figures, and interpretations into a comprehensive report detailing the impacts of beekeeping on wild bee diversity and pollination networks.\\n            </Instruction>\\n            <SubSteps>\\n                <SubStep>\\n                    <Description>Create Report Structure</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Organize the report into sections such as Introduction, Methods, Results, Discussion, and Conclusion.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Example using R Markdown\\n                            # Create a new R Markdown file and include necessary sections\\n                            rmarkdown::draft(\"Bee_Analysis_Report.Rmd\", template = \"html_document\", package = \"rmarkdown\")\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Incorporate Results and Figures</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Insert the saved summaries, network indices, PAC results, and visualizations into the respective sections of the report.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Example R Markdown inclusion\\n                            # In the Rmd file, include code chunks to read and display results\\n                            # ```{r GLMM_Summary}\\n                            # readLines(\"GLMM_Abundance_Summary.txt\")\\n                            # ```\\n                            # \\n                            # ```{r Network_Indices}\\n                            # network_indices <- read.csv(\"Pollination_Network_Indices.csv\")\\n                            # print(network_indices)\\n                            # ```\\n                            # \\n                            # Include plots by referencing the saved plot objects or regenerating them\\n                            # ```{r VIF_Plot, fig.height=6, fig.width=8}\\n                            # print(vif_plot)\\n                            # ```\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Finalize and Knit Report</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Review the report for completeness and accuracy, then knit it to the desired format (e.g., PDF, HTML).\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Knit the report\\n                            rmarkdown::render(\"Bee_Analysis_Report.Rmd\")\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n            </SubSteps>\\n        </Details>\\n    </Step>\\n</AnalysisPlan>\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 5620, 'prompt_tokens': 18218, 'total_tokens': 23838, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o1-mini-2024-09-12', 'system_fingerprint': 'fp_f56e40de61', 'finish_reason': 'stop', 'logprobs': None}, id='run-a320bf73-ceaf-4936-87bb-fe0f9f301d0f-0', usage_metadata={'input_tokens': 18218, 'output_tokens': 5620, 'total_tokens': 23838, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 256}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan_analyses_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor_chain = executor_prompt | executor_llm\n",
    "executed_plan_steps = executor_chain.invoke({\n",
    "    \"analysis_plan_xml\": plan_analyses_xml,\n",
    "    \"dataset_summary\": dataset_summary\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### **R Script Generation for Analysis Plan**\n",
       "\n",
       "Based on the provided **AnalysisPlan** in XML and the **Dataset Summary**, separate R scripts have been generated for each analysis step. Additionally, a master R script has been created to execute all individual scripts in a structured manner.\n",
       "\n",
       "---\n",
       "\n",
       "#### **Instructions to Save the Scripts**\n",
       "\n",
       "1. **Directory Structure:**\n",
       "   \n",
       "   - Create a main project directory.\n",
       "   - Inside the main directory, create a subdirectory named `scripts` to store all individual R scripts.\n",
       "\n",
       "2. **Saving Individual Scripts:**\n",
       "   \n",
       "   - Save each analysis step as a separate `.R` file within the `scripts` folder.\n",
       "   - Use descriptive filenames corresponding to each analysis step, e.g., `Step1_LoadRequiredLibraries.R`, `Step2_ImportAndInspectDataset.R`, etc.\n",
       "\n",
       "3. **Master Script:**\n",
       "   \n",
       "   - Save the master script as `MasterScript.R` in the main project directory (outside the `scripts` folder).\n",
       "   - This script will sequentially execute all individual analysis scripts.\n",
       "\n",
       "---\n",
       "\n",
       "### **Individual R Scripts**\n",
       "\n",
       "---\n",
       "\n",
       "#### **Step 1: Load Required Libraries**\n",
       "\n",
       "**Filename:** `scripts/Step1_LoadRequiredLibraries.R`\n",
       "\n",
       "**Description:** Install and load all necessary R packages required for the analysis.\n",
       "\n",
       "```r\n",
       "# Step1_LoadRequiredLibraries.R\n",
       "\n",
       "# Install packages if not already installed\n",
       "required_packages <- c(\"lme4\", \"MuMIn\", \"car\", \"r2glmm\", \"piecewiseSEM\", \n",
       "                       \"bipartite\", \"dplyr\", \"tidyr\", \"emmeans\", \"corrr\", \"vegan\", \"ggplot2\", \"rmarkdown\")\n",
       "installed_packages <- rownames(installed.packages())\n",
       "for(pkg in required_packages){\n",
       "    if(!pkg %in% installed_packages){\n",
       "        install.packages(pkg, dependencies = TRUE)\n",
       "    }\n",
       "}\n",
       "\n",
       "# Load libraries\n",
       "library(lme4)\n",
       "library(MuMIn)\n",
       "library(car)\n",
       "library(r2glmm)\n",
       "library(piecewiseSEM)\n",
       "library(bipartite)\n",
       "library(dplyr)\n",
       "library(tidyr)\n",
       "library(emmeans)\n",
       "library(corrr)\n",
       "library(vegan)\n",
       "library(ggplot2)\n",
       "library(rmarkdown)\n",
       "\n",
       "# Alternative Analyses Suggestions:\n",
       "# Consider using 'tidyverse' for comprehensive data manipulation.\n",
       "# For advanced visualization, 'ggplot2' is included, but packages like 'plotly' can offer interactive plots.\n",
       "```\n",
       "\n",
       "**Comments:**\n",
       "\n",
       "- **1.2 Suitability Check:** All listed packages are suitable for statistical modeling, data manipulation, and network analysis as required by the analysis plan.\n",
       "  \n",
       "- **1.3 Alternative Suggestions:** Comments have been added to suggest additional packages like `tidyverse` for broader data manipulation capabilities and `plotly` for interactive visualizations.\n",
       "\n",
       "---\n",
       "\n",
       "#### **Step 2: Import and Inspect Dataset**\n",
       "\n",
       "**Filename:** `scripts/Step2_ImportAndInspectDataset.R`\n",
       "\n",
       "**Description:** Load the dataset into R and perform initial inspections to understand its structure and identify any missing or inconsistent data.\n",
       "\n",
       "```r\n",
       "# Step2_ImportAndInspectDataset.R\n",
       "\n",
       "# Replace 'your_dataset.csv' with the actual file name and path\n",
       "wild_bee_data <- read.csv(\"your_dataset.csv\", stringsAsFactors = TRUE)\n",
       "\n",
       "# View the first few rows\n",
       "head(wild_bee_data)\n",
       "\n",
       "# Summary statistics\n",
       "summary(wild_bee_data)\n",
       "\n",
       "# Check for missing values\n",
       "sapply(wild_bee_data, function(x) sum(is.na(x)))\n",
       "\n",
       "# Alternative Analyses Suggestions:\n",
       "# Use 'glimpse(wild_bee_data)' from dplyr for a transposed view of the data structure.\n",
       "# Utilize 'skimr::skim(wild_bee_data)' for a more detailed summary (requires installing 'skimr').\n",
       "```\n",
       "\n",
       "**Comments:**\n",
       "\n",
       "- **1.2 Suitability Check:** The dataset is being read with `stringsAsFactors = TRUE`, which is appropriate for categorical variables as per the data summary. Ensure that all categorical variables are correctly identified.\n",
       "  \n",
       "- **1.3 Alternative Suggestions:** Comments suggest using `glimpse` for an alternative data overview and `skimr::skim` for a more comprehensive summary, enhancing data inspection.\n",
       "\n",
       "---\n",
       "\n",
       "#### **Step 3: Data Preprocessing**\n",
       "\n",
       "**Filename:** `scripts/Step3_DataPreprocessing.R`\n",
       "\n",
       "**Description:** Prepare the data for analysis by handling missing values, encoding categorical variables, and scaling numerical variables as required.\n",
       "\n",
       "```r\n",
       "# Step3_DataPreprocessing.R\n",
       "\n",
       "# Load necessary libraries\n",
       "library(dplyr)\n",
       "\n",
       "# 3.1 Handle Missing Values\n",
       "# Strategy: Remove rows with missing values\n",
       "wild_bee_data <- na.omit(wild_bee_data)\n",
       "\n",
       "# Alternative Suggestions:\n",
       "# Consider multiple imputation using the 'mice' package if data loss from omission is a concern.\n",
       "\n",
       "# 3.2 Encode Categorical Variables\n",
       "# Convert categorical variables to factors using variable names from the data summary\n",
       "categorical_vars <- c(\"Island\", \"Island_Site\", \"family\", \"InsectSpecies\", \"Apis\")\n",
       "wild_bee_data[categorical_vars] <- lapply(wild_bee_data[categorical_vars], as.factor)\n",
       "\n",
       "# Alternative Suggestions:\n",
       "# Use 'forcats' package for more nuanced factor manipulation, such as releveling or collapsing categories.\n",
       "\n",
       "# 3.3 Scale Numerical Variables\n",
       "# Define numerical variables based on the data summary\n",
       "numeric_vars <- c(\"NumberHivesMinistry2005_2015\", \n",
       "                  \"HiveDensityMinistry2005-2015\",\n",
       "                  \"HiveDensityMinistry_STUDYYEAR\", \n",
       "                  \"NumberApis\", \n",
       "                  \"FlowerAbundance\",\n",
       "                  \"FlowerRichness\", \n",
       "                  \"LandscapeHeterogeneity\", \n",
       "                  \"Areakm2\",\n",
       "                  \"%NaturalHabitats\")\n",
       "\n",
       "# Scale numerical predictors\n",
       "wild_bee_data[numeric_vars] <- scale(wild_bee_data[numeric_vars])\n",
       "\n",
       "# Alternative Suggestions:\n",
       "# Explore robust scaling methods using the 'scale' function with parameters or using the 'scale' function from 'caret'.\n",
       "\n",
       "# Additional Check:\n",
       "# Verify the scaling\n",
       "summary(wild_bee_data[numeric_vars])\n",
       "```\n",
       "\n",
       "**Comments:**\n",
       "\n",
       "- **1.2 Suitability Check:** \n",
       "  - **Handling Missing Values:** The chosen strategy (`na.omit`) is suitable given the dataset size. However, alternative strategies like imputation might preserve more data.\n",
       "  - **Encoding Categorical Variables:** Converting specified variables to factors aligns with their types in the data summary.\n",
       "  - **Scaling Numerical Variables:** Scaling is appropriate for models sensitive to variable scaling (e.g., GLMMs).\n",
       "\n",
       "- **1.3 Alternative Suggestions:** Comments suggest alternative packages and methods for imputation, factor manipulation, and scaling to enhance preprocessing flexibility.\n",
       "\n",
       "---\n",
       "\n",
       "#### **Step 4: Generalized Linear Mixed Models (GLMMs)**\n",
       "\n",
       "**Filename:** `scripts/Step4_GLMMS.R`\n",
       "\n",
       "**Description:** Analyze the relationship between honey bee visitation rate and wild bee abundance and richness using GLMMs.\n",
       "\n",
       "```r\n",
       "# Step4_GLMMS.R\n",
       "\n",
       "# Load necessary libraries\n",
       "library(lme4)\n",
       "library(MuMIn)\n",
       "library(car)\n",
       "library(r2glmm)\n",
       "\n",
       "# 4.1 Model Wild Bee Abundance\n",
       "# Fit a GLMM for wild bee abundance with honey bee visitation rate and other predictors.\n",
       "# Include 'Island' as a random effect and use a Gamma distribution with a log link function.\n",
       "\n",
       "abundance_model <- glmer(WildBeeAbundanceSt ~ NumberApis + FlowerAbundance + FlowerRichness + \n",
       "                             LandscapeHeterogeneity + log(Areakm2) + \n",
       "                             (1 | Island), \n",
       "                         data = wild_bee_data, \n",
       "                         family = Gamma(link = \"log\"))\n",
       "\n",
       "summary(abundance_model)\n",
       "\n",
       "# Alternative Analyses Suggestions:\n",
       "# If the Gamma distribution is not appropriate, consider a Poisson or Negative Binomial distribution for count data.\n",
       "\n",
       "# 4.2 Model Wild Bee Richness\n",
       "# Fit a GLMM for wild bee richness using the same predictors and random effect as above.\n",
       "\n",
       "richness_model <- glmer(WildBeeRichnessSt ~ NumberApis + FlowerAbundance + FlowerRichness + \n",
       "                            LandscapeHeterogeneity + log(Areakm2) + \n",
       "                            (1 | Island), \n",
       "                        data = wild_bee_data, \n",
       "                        family = Gamma(link = \"log\"))\n",
       "\n",
       "summary(richness_model)\n",
       "\n",
       "# Alternative Analyses Suggestions:\n",
       "# For richness data, a Poisson or Zero-Inflated model might be more suitable if overdispersion is an issue.\n",
       "\n",
       "# 4.3 Model Selection with Dredge\n",
       "# Perform model selection using the dredge function to identify the best models with up to 4 predictors.\n",
       "\n",
       "# Set global options for MuMIn\n",
       "options(na.action = \"na.fail\")\n",
       "\n",
       "# Model selection for abundance\n",
       "abundance_dredge <- dredge(abundance_model, m.lim = c(0,4))\n",
       "print(abundance_dredge)\n",
       "\n",
       "# Select the best model\n",
       "best_abundance_model <- get.models(abundance_dredge, subset = 1)[[1]]\n",
       "summary(best_abundance_model)\n",
       "\n",
       "# Model selection for richness\n",
       "richness_dredge <- dredge(richness_model, m.lim = c(0,4))\n",
       "print(richness_dredge)\n",
       "\n",
       "# Select the best model\n",
       "best_richness_model <- get.models(richness_dredge, subset = 1)[[1]]\n",
       "summary(best_richness_model)\n",
       "\n",
       "# Alternative Analyses Suggestions:\n",
       "# Consider using AICc for model selection or other criteria like BIC based on research priorities.\n",
       "```\n",
       "\n",
       "**Comments:**\n",
       "\n",
       "- **1.2 Suitability Check:** \n",
       "  - **GLMMs for Abundance and Richness:** Both models are appropriately specified for continuous dependent variables using the Gamma family. Ensure that the Gamma distribution fits the data well; check residuals and dispersion.\n",
       "  \n",
       "- **1.3 Alternative Suggestions:** \n",
       "  - For both models, alternative distributions like Poisson, Negative Binomial, or Zero-Inflated models are suggested depending on the data's characteristics (e.g., count data, overdispersion).\n",
       "\n",
       "---\n",
       "\n",
       "#### **Step 5: Variation Inflation Factor (VIF) Analysis**\n",
       "\n",
       "**Filename:** `scripts/Step5_VIFAnalysis.R`\n",
       "\n",
       "**Description:** Identify and address multicollinearity among landscape variables using VIF.\n",
       "\n",
       "```r\n",
       "# Step5_VIFAnalysis.R\n",
       "\n",
       "# Load necessary libraries\n",
       "library(car)\n",
       "\n",
       "# 5.1 Calculate VIF for the best abundance model\n",
       "vif_abundance <- vif(best_abundance_model)\n",
       "print(vif_abundance)\n",
       "\n",
       "# 5.2 Calculate VIF for the best richness model\n",
       "vif_richness <- vif(best_richness_model)\n",
       "print(vif_richness)\n",
       "\n",
       "# 5.3 Interpret VIF results\n",
       "# Typically, VIF > 5 or 10 indicates multicollinearity issues.\n",
       "\n",
       "if(any(vif_abundance > 5)){\n",
       "    warning(\"High VIF detected in abundance model. Consider removing or combining variables.\")\n",
       "}\n",
       "\n",
       "if(any(vif_richness > 5)){\n",
       "    warning(\"High VIF detected in richness model. Consider removing or combining variables.\")\n",
       "}\n",
       "\n",
       "# Alternative Analyses Suggestions:\n",
       "# Consider using Principal Component Analysis (PCA) to reduce dimensionality if multicollinearity is present.\n",
       "```\n",
       "\n",
       "**Comments:**\n",
       "\n",
       "- **1.2 Suitability Check:** VIF is an appropriate method to detect multicollinearity among predictor variables in the models.\n",
       "  \n",
       "- **1.3 Alternative Suggestions:** Suggests PCA as an alternative method to handle multicollinearity by reducing the number of predictors.\n",
       "\n",
       "---\n",
       "\n",
       "#### **Step 6: Piecewise Structural Equation Modeling (SEM)**\n",
       "\n",
       "**Filename:** `scripts/Step6_PiecewiseSEM.R`\n",
       "\n",
       "**Description:** Summarize direct and indirect effects of honey bee visitation rate on wild bee network metrics using Piecewise SEM.\n",
       "\n",
       "```r\n",
       "# Step6_PiecewiseSEM.R\n",
       "\n",
       "# Load necessary libraries\n",
       "library(piecewiseSEM)\n",
       "library(lme4)\n",
       "\n",
       "# 6.1 Scale Variables\n",
       "wild_bee_data_scaled <- wild_bee_data %>%\n",
       "    mutate_at(vars(NumberApis, FlowerAbundance, FlowerRichness, \n",
       "                   LandscapeHeterogeneity, Areakm2, \n",
       "                   WildBeeAbundanceSt, WildBeeRichnessSt), scale)\n",
       "\n",
       "# 6.2 Define SEM Model\n",
       "sem_model <- psem(\n",
       "    glmer(WildBeeAbundanceSt ~ NumberApis + FlowerAbundance + FlowerRichness + \n",
       "              LandscapeHeterogeneity + log(Areakm2) + \n",
       "              (1 | Island), \n",
       "          data = wild_bee_data_scaled, \n",
       "          family = Gamma(link = \"log\")),\n",
       "    \n",
       "    glmer(WildBeeRichnessSt ~ NumberApis + FlowerAbundance + FlowerRichness + \n",
       "              LandscapeHeterogeneity + log(Areakm2) + \n",
       "              (1 | Island), \n",
       "          data = wild_bee_data_scaled, \n",
       "          family = Gamma(link = \"log\")),\n",
       "    \n",
       "    lm(log(Areakm2) ~ NumberApis + FlowerAbundance + \n",
       "              FlowerRichness + LandscapeHeterogeneity, \n",
       "       data = wild_bee_data_scaled),\n",
       "    \n",
       "    lm(NumberApis ~ FlowerAbundance + FlowerRichness + LandscapeHeterogeneity, \n",
       "       data = wild_bee_data_scaled)\n",
       ")\n",
       "\n",
       "# 6.3 Fit SEM Model and Assess Fit\n",
       "sem_fit <- sem.fit(sem_model, data = wild_bee_data_scaled)\n",
       "summary(sem_fit, standardize = TRUE, fit.measures = TRUE)\n",
       "\n",
       "# Goodness-of-fit tests\n",
       "sem_fit_standard <- sem.fit(sem_model, data = wild_bee_data_scaled, test = \"standard\")\n",
       "summary(sem_fit_standard)\n",
       "\n",
       "# Alternative Analyses Suggestions:\n",
       "# Explore alternative model specifications or include additional latent variables if theoretical justification exists.\n",
       "```\n",
       "\n",
       "**Comments:**\n",
       "\n",
       "- **1.2 Suitability Check:** \n",
       "  - **Scaling Variables:** Scaling is appropriately performed for variables to ensure model convergence and interpretability.\n",
       "  - **SEM Specification:** The model correctly specifies relationships among variables, aligning with the dataset's structure.\n",
       "\n",
       "- **1.3 Alternative Suggestions:** \n",
       "  - Encourages exploration of alternative SEM specifications and the inclusion of latent variables where appropriate.\n",
       "\n",
       "---\n",
       "\n",
       "#### **Step 7: Pollination Network Analysis**\n",
       "\n",
       "**Filename:** `scripts/Step7_PollinationNetworkAnalysis.R`\n",
       "\n",
       "**Description:** Construct and analyze pollination networks using the `bipartite` package.\n",
       "\n",
       "```r\n",
       "# Step7_PollinationNetworkAnalysis.R\n",
       "\n",
       "# Load necessary libraries\n",
       "library(bipartite)\n",
       "\n",
       "# 7.1 Construct Bipartite Networks\n",
       "# Replace 'pollination_network.csv' with the actual file name and path\n",
       "pollination_data <- read.csv(\"pollination_network.csv\", stringsAsFactors = TRUE)\n",
       "\n",
       "# Create a bipartite matrix\n",
       "bipartite_matrix <- with(pollination_data, table(PlantSpecies, PollinatorSpecies))\n",
       "\n",
       "# Convert to matrix\n",
       "bipartite_matrix <- as.matrix(bipartite_matrix)\n",
       "\n",
       "# Alternative Analyses Suggestions:\n",
       "# For more detailed network structures, consider using graph-based packages like 'igraph'.\n",
       "\n",
       "# 7.2 Calculate Network Indices\n",
       "\n",
       "# Number of links\n",
       "num_links <- networklevel(bipartite_matrix, index = \"links\")\n",
       "\n",
       "# Number of plant species\n",
       "num_plants <- networklevel(bipartite_matrix, index = \"species.level\")\n",
       "\n",
       "# Linkage density\n",
       "linkage_density <- linkage(bipartite_matrix)\n",
       "\n",
       "# Nestedness\n",
       "nestedness <- networklevel(bipartite_matrix, index = \"weighted NODF\")\n",
       "\n",
       "# Modularity\n",
       "modularity <- networklevel(bipartite_matrix, index = \"module\")\n",
       "\n",
       "# Combine indices into a dataframe\n",
       "network_indices <- data.frame(\n",
       "    NumberOfLinks = num_links,\n",
       "    NumberOfPlantSpecies = num_plants,\n",
       "    LinkageDensity = linkage_density,\n",
       "    Nestedness = nestedness,\n",
       "    Modularity = modularity\n",
       ")\n",
       "\n",
       "# 7.3 Assess Against Null Models\n",
       "# Calculate z-scores using the 'vaznull' null model\n",
       "null_model <- NULLMODEL(bipartite_matrix, method = \"vaznull\")\n",
       "\n",
       "z_linkage_density <- null_model$zLinkage\n",
       "z_nestedness <- null_model$zNODF\n",
       "z_modularity <- null_model$zModularity\n",
       "\n",
       "# Add z-scores to network_indices\n",
       "network_indices$Z_LinkageDensity <- z_linkage_density\n",
       "network_indices$Z_Nestedness <- z_nestedness\n",
       "network_indices$Z_Modularity <- z_modularity\n",
       "\n",
       "# Alternative Analyses Suggestions:\n",
       "# Explore other null model methods provided by the 'bipartite' package to validate robustness.\n",
       "```\n",
       "\n",
       "**Comments:**\n",
       "\n",
       "- **1.2 Suitability Check:** \n",
       "  - **Bipartite Networks:** Suitable for analyzing plant-pollinator interactions as per the dataset.\n",
       "  \n",
       "- **1.3 Alternative Suggestions:** \n",
       "  - Suggests using `igraph` for more complex network analyses, providing flexibility beyond bipartite matrices.\n",
       "\n",
       "---\n",
       "\n",
       "#### **Step 8: Potential Competition Analysis**\n",
       "\n",
       "**Filename:** `scripts/Step8_PotentialCompetitionAnalysis.R`\n",
       "\n",
       "**Description:** Measure species niche overlap using the Apparent Competition Index as per Müller et al. (1999).\n",
       "\n",
       "```r\n",
       "# Step8_PotentialCompetitionAnalysis.R\n",
       "\n",
       "# Load necessary libraries\n",
       "library(vegan)\n",
       "\n",
       "# 8.1 Prepare Species Interaction Matrix\n",
       "# Transpose the bipartite matrix for alignment\n",
       "transposed_matrix <- t(bipartite_matrix)\n",
       "\n",
       "# Ensure the matrix is binary (presence/absence)\n",
       "transposed_matrix[transposed_matrix > 0] <- 1\n",
       "\n",
       "# Alternative Analyses Suggestions:\n",
       "# Use other niche overlap indices like Pianka’s or Schoener’s for comparative analysis.\n",
       "\n",
       "# 8.2 Calculate Apparent Competition Index (PAC)\n",
       "# Note: Specific PAC calculation requires defined formula. Using nicheOverlap as a proxy.\n",
       "\n",
       "# Calculate niche overlap using Pianka's index\n",
       "niche_overlap <- nicheOverlap(transposed_matrix, method = \"Pianka\")\n",
       "\n",
       "# Placeholder for Apparent Competition Index if specific formula is needed\n",
       "# Example PAC calculation (modify as per Müller et al. (1999) formula):\n",
       "# PAC <- (sum of shared resources) / (sum of total resources per species)\n",
       "\n",
       "# Since PAC is specific, ensure the correct formula is implemented here based on the study.\n",
       "# Alternatively, consult relevant ecological packages or literature for precise implementation.\n",
       "\n",
       "# Alternative Analyses Suggestions:\n",
       "# If PAC calculation is complex, consider consulting specialized ecological analysis packages or scripts.\n",
       "```\n",
       "\n",
       "**Comments:**\n",
       "\n",
       "- **1.2 Suitability Check:** \n",
       "  - **Niche Overlap Calculation:** Using `nicheOverlap` from the `vegan` package is appropriate for assessing species niche overlap, aligning with PAC objectives.\n",
       "  \n",
       "- **1.3 Alternative Suggestions:** \n",
       "  - Suggests exploring other indices and ensuring the specific PAC formula is correctly implemented based on the referenced study.\n",
       "\n",
       "---\n",
       "\n",
       "#### **Step 9: A Posteriori Tests for Differences Between Slopes**\n",
       "\n",
       "**Filename:** `scripts/Step9_APosterioriTests.R`\n",
       "\n",
       "**Description:** Perform post-hoc tests to examine differences between slopes for each wild bee family using the `emtrends` function from the `emmeans` package.\n",
       "\n",
       "```r\n",
       "# Step9_APosterioriTests.R\n",
       "\n",
       "# Load necessary libraries\n",
       "library(lme4)\n",
       "library(emmeans)\n",
       "\n",
       "# 9.1 Fit Interaction Models\n",
       "\n",
       "# Interaction model for abundance\n",
       "interaction_model_abundance <- glmer(WildBeeAbundanceSt ~ NumberApis * family + FlowerAbundance + \n",
       "                                         FlowerRichness + LandscapeHeterogeneity + log(Areakm2) + \n",
       "                                         (1 | Island), \n",
       "                                     data = wild_bee_data, \n",
       "                                     family = Gamma(link = \"log\"))\n",
       "\n",
       "# Interaction model for richness\n",
       "interaction_model_richness <- glmer(WildBeeRichnessSt ~ NumberApis * family + FlowerAbundance + \n",
       "                                        FlowerRichness + LandscapeHeterogeneity + log(Areakm2) + \n",
       "                                        (1 | Island), \n",
       "                                    data = wild_bee_data, \n",
       "                                    family = Gamma(link = \"log\"))\n",
       "\n",
       "# 9.2 Perform Emtrends Analysis\n",
       "\n",
       "# Emtrends for abundance\n",
       "emtrends_abundance <- emtrends(interaction_model_abundance, \n",
       "                              pairwise ~ family, \n",
       "                              var = \"NumberApis\")\n",
       "summary(emtrends_abundance)\n",
       "\n",
       "# Emtrends for richness\n",
       "emtrends_richness <- emtrends(interaction_model_richness, \n",
       "                             pairwise ~ family, \n",
       "                             var = \"NumberApis\")\n",
       "summary(emtrends_richness)\n",
       "\n",
       "# Alternative Analyses Suggestions:\n",
       "# Consider using `multcomp` package for multiple comparisons if alternative methods are preferred.\n",
       "```\n",
       "\n",
       "**Comments:**\n",
       "\n",
       "- **1.2 Suitability Check:** \n",
       "  - **Interaction Models:** Appropriately include interaction terms between `NumberApis` and `family` to assess slope differences.\n",
       "  \n",
       "- **1.3 Alternative Suggestions:** \n",
       "  - Suggests using the `multcomp` package as an alternative for performing multiple comparisons.\n",
       "\n",
       "---\n",
       "\n",
       "#### **Step 10: Export and Document Results**\n",
       "\n",
       "**Filename:** `scripts/Step10_ExportAndDocumentResults.R`\n",
       "\n",
       "**Description:** Save all model outputs, summaries, and important statistics to files for reporting and further analysis.\n",
       "\n",
       "```r\n",
       "# Step10_ExportAndDocumentResults.R\n",
       "\n",
       "# 10.1 Save Model Summaries\n",
       "\n",
       "# Save GLMM summaries\n",
       "sink(\"GLMM_Abundance_Summary.txt\")\n",
       "summary(best_abundance_model)\n",
       "sink()\n",
       "\n",
       "sink(\"GLMM_Richness_Summary.txt\")\n",
       "summary(best_richness_model)\n",
       "sink()\n",
       "\n",
       "# Save SEM summary\n",
       "sink(\"SEM_Summary.txt\")\n",
       "summary(sem_fit, standardize = TRUE, fit.measures = TRUE)\n",
       "sink()\n",
       "\n",
       "# Save Emtrends summaries\n",
       "sink(\"Emtrends_Abundance_Summary.txt\")\n",
       "summary(emtrends_abundance)\n",
       "sink()\n",
       "\n",
       "sink(\"Emtrends_Richness_Summary.txt\")\n",
       "summary(emtrends_richness)\n",
       "sink()\n",
       "\n",
       "# Alternative Analyses Suggestions:\n",
       "# Consider exporting summaries in HTML or PDF formats for better readability using R Markdown.\n",
       "\n",
       "# 10.2 Save Network Indices\n",
       "write.csv(network_indices, \"Pollination_Network_Indices.csv\", row.names = FALSE)\n",
       "\n",
       "# 10.3 Save PAC Results\n",
       "write.csv(niche_overlap, \"Apparent_Competition_Index.csv\", row.names = TRUE)\n",
       "\n",
       "# Alternative Analyses Suggestions:\n",
       "# Use `saveRDS` for saving R objects if further R-based analysis is required.\n",
       "```\n",
       "\n",
       "**Comments:**\n",
       "\n",
       "- **1.2 Suitability Check:** \n",
       "  - **Exporting Results:** The chosen methods (`sink`, `write.csv`) are appropriate for exporting textual summaries and dataframes.\n",
       "\n",
       "- **1.3 Alternative Suggestions:** \n",
       "  - Suggests using R Markdown for more formatted and readable report exports and `saveRDS` for preserving R objects.\n",
       "\n",
       "---\n",
       "\n",
       "#### **Step 11: Visualization of Results**\n",
       "\n",
       "**Filename:** `scripts/Step11_VisualizationOfResults.R`\n",
       "\n",
       "**Description:** Create visualizations to illustrate the findings from the statistical analyses, such as effect plots, network diagrams, and VIF plots.\n",
       "\n",
       "```r\n",
       "# Step11_VisualizationOfResults.R\n",
       "\n",
       "# Load necessary libraries\n",
       "library(emmeans)\n",
       "library(ggplot2)\n",
       "library(bipartite)\n",
       "\n",
       "# 11.1 Effect Plots for GLMMs\n",
       "\n",
       "# Plot for abundance\n",
       "plot(emtrends_abundance, comparisons = TRUE) +\n",
       "    ggtitle(\"Effect of NumberApis on Wild Bee Abundance by Family\") +\n",
       "    theme_minimal()\n",
       "\n",
       "# Save the plot\n",
       "ggsave(\"EffectPlot_Abundance.png\")\n",
       "\n",
       "# Plot for richness\n",
       "plot(emtrends_richness, comparisons = TRUE) +\n",
       "    ggtitle(\"Effect of NumberApis on Wild Bee Richness by Family\") +\n",
       "    theme_minimal()\n",
       "\n",
       "# Save the plot\n",
       "ggsave(\"EffectPlot_Richness.png\")\n",
       "\n",
       "# Alternative Analyses Suggestions:\n",
       "# Enhance plots with custom themes or interactivity using packages like `plotly`.\n",
       "\n",
       "# 11.2 Network Diagrams\n",
       "\n",
       "# Basic network plot\n",
       "plotweb(bipartite_matrix, method = \"normal\", \n",
       "        title = \"Pollination Network\", \n",
       "        text.rot = 90, text.spacing = 0.5)\n",
       "\n",
       "# Save the plot\n",
       "ggsave(\"Pollination_Network.png\")\n",
       "\n",
       "# Alternative Analyses Suggestions:\n",
       "# Use `igraph` for more customizable and interactive network visualizations.\n",
       "\n",
       "# 11.3 VIF Plot\n",
       "\n",
       "# Calculate VIF\n",
       "vif_values <- vif(best_abundance_model)\n",
       "vif_df <- data.frame(Variable = names(vif_values), VIF = vif_values)\n",
       "\n",
       "# Create VIF plot\n",
       "vif_plot <- ggplot(vif_df, aes(x = reorder(Variable, VIF), y = VIF)) +\n",
       "    geom_bar(stat = \"identity\", fill = \"steelblue\") +\n",
       "    coord_flip() +\n",
       "    geom_hline(yintercept = 5, linetype = \"dashed\", color = \"red\") +\n",
       "    labs(title = \"VIF Values for Predictors\",\n",
       "         x = \"Variables\",\n",
       "         y = \"VIF\") +\n",
       "    theme_minimal()\n",
       "\n",
       "# Display the plot\n",
       "print(vif_plot)\n",
       "\n",
       "# Save the plot\n",
       "ggsave(\"VIF_Plot.png\", plot = vif_plot)\n",
       "\n",
       "# Alternative Analyses Suggestions:\n",
       "# Annotate the plot with labels for VIF values or use color gradients to indicate severity.\n",
       "```\n",
       "\n",
       "**Comments:**\n",
       "\n",
       "- **1.2 Suitability Check:** \n",
       "  - **Visualization Techniques:** The selected plotting methods (`ggplot2`, `plotweb`) are suitable for visualizing model effects, network structures, and VIF values.\n",
       "\n",
       "- **1.3 Alternative Suggestions:** \n",
       "  - Suggests enhancing plots with additional features or interactivity for improved interpretability and presentation.\n",
       "\n",
       "---\n",
       "\n",
       "#### **Step 12: Report Findings**\n",
       "\n",
       "**Filename:** `scripts/Step12_ReportFindings.R`\n",
       "\n",
       "**Description:** Compile all results, figures, and interpretations into a comprehensive report detailing the impacts of beekeeping on wild bee diversity and pollination networks.\n",
       "\n",
       "```r\n",
       "# Step12_ReportFindings.R\n",
       "\n",
       "# Load necessary library\n",
       "library(rmarkdown)\n",
       "\n",
       "# 12.1 Create Report Structure\n",
       "# Create a new R Markdown file with necessary sections\n",
       "rmarkdown::draft(\"Bee_Analysis_Report.Rmd\", template = \"html_document\", package = \"rmarkdown\")\n",
       "\n",
       "# 12.2 Incorporate Results and Figures\n",
       "# Instructions (to be performed manually in the R Markdown file):\n",
       "# - Insert code chunks to read and display saved summaries.\n",
       "# - Example code chunks to include in 'Bee_Analysis_Report.Rmd':\n",
       "#\n",
       "# ```{r GLMM_Summary}\n",
       "# cat(readLines(\"GLMM_Abundance_Summary.txt\"), sep = \"\\n\")\n",
       "# ```\n",
       "#\n",
       "# ```{r Network_Indices}\n",
       "# network_indices <- read.csv(\"Pollination_Network_Indices.csv\")\n",
       "# knitr::kable(network_indices)\n",
       "# ```\n",
       "#\n",
       "# ```{r VIF_Plot, fig.height=6, fig.width=8}\n",
       "# vif_plot <- ggplot(vif_df, aes(x = reorder(Variable, VIF), y = VIF)) +\n",
       "#     geom_bar(stat = \"identity\", fill = \"steelblue\") +\n",
       "#     coord_flip() +\n",
       "#     geom_hline(yintercept = 5, linetype = \"dashed\", color = \"red\") +\n",
       "#     labs(title = \"VIF Values for Predictors\",\n",
       "#          x = \"Variables\",\n",
       "#          y = \"VIF\") +\n",
       "#     theme_minimal()\n",
       "# print(vif_plot)\n",
       "# ```\n",
       "#\n",
       "# - Similarly, include other summaries and plots as needed.\n",
       "\n",
       "# 12.3 Finalize and Knit Report\n",
       "# After manually incorporating all necessary content, render the R Markdown report.\n",
       "\n",
       "# Knit the report to HTML format\n",
       "rmarkdown::render(\"Bee_Analysis_Report.Rmd\")\n",
       "\n",
       "# Alternative Analyses Suggestions:\n",
       "# Customize the R Markdown template to match the desired report aesthetics and structure.\n",
       "```\n",
       "\n",
       "**Comments:**\n",
       "\n",
       "- **1.2 Suitability Check:** \n",
       "  - **Report Generation:** Using R Markdown is suitable for compiling a comprehensive report that integrates text, code, and visualizations.\n",
       "  \n",
       "- **1.3 Alternative Suggestions:** \n",
       "  - Suggests customizing the R Markdown template to better fit specific reporting needs and aesthetics.\n",
       "\n",
       "---\n",
       "\n",
       "### **Master R Script**\n",
       "\n",
       "**Filename:** `MasterScript.R`\n",
       "\n",
       "**Description:** Master script to execute all individual analysis scripts in a structured manner.\n",
       "\n",
       "```r\n",
       "# MasterScript.R\n",
       "\n",
       "# Set working directory to the project folder\n",
       "# setwd(\"path_to_your_project_folder\")  # Uncomment and set your project directory path\n",
       "\n",
       "# Source individual scripts in order\n",
       "source(\"scripts/Step1_LoadRequiredLibraries.R\")\n",
       "source(\"scripts/Step2_ImportAndInspectDataset.R\")\n",
       "source(\"scripts/Step3_DataPreprocessing.R\")\n",
       "source(\"scripts/Step4_GLMMS.R\")\n",
       "source(\"scripts/Step5_VIFAnalysis.R\")\n",
       "source(\"scripts/Step6_PiecewiseSEM.R\")\n",
       "source(\"scripts/Step7_PollinationNetworkAnalysis.R\")\n",
       "source(\"scripts/Step8_PotentialCompetitionAnalysis.R\")\n",
       "source(\"scripts/Step9_APosterioriTests.R\")\n",
       "source(\"scripts/Step10_ExportAndDocumentResults.R\")\n",
       "source(\"scripts/Step11_VisualizationOfResults.R\")\n",
       "source(\"scripts/Step12_ReportFindings.R\")\n",
       "\n",
       "# Inform the user that all scripts have been run\n",
       "cat(\"All analysis scripts have been successfully executed.\\n\")\n",
       "```\n",
       "\n",
       "**Comments:**\n",
       "\n",
       "- **Execution Flow:** The master script sequentially sources each individual analysis script, ensuring that all steps are performed in the correct order.\n",
       "  \n",
       "- **Customization:** Users should set their working directory appropriately by uncommenting and modifying the `setwd()` function as needed.\n",
       "\n",
       "---\n",
       "\n",
       "### **Summary of Script Saving**\n",
       "\n",
       "1. **Create Project Directory:**\n",
       "   \n",
       "   - Choose a suitable location on your computer and create a new folder for the project, e.g., `Bee_Analysis_Project`.\n",
       "\n",
       "2. **Create Scripts Subdirectory:**\n",
       "   \n",
       "   - Inside `Bee_Analysis_Project`, create a subfolder named `scripts`.\n",
       "\n",
       "3. **Save Individual Scripts:**\n",
       "   \n",
       "   - Save each of the individual `.R` scripts (Steps 1 to 12) into the `scripts` folder with the filenames as specified above.\n",
       "\n",
       "4. **Save Master Script:**\n",
       "   \n",
       "   - Save the `MasterScript.R` file directly inside `Bee_Analysis_Project`.\n",
       "\n",
       "5. **Run the Master Script:**\n",
       "   \n",
       "   - Open R or RStudio, set the working directory to `Bee_Analysis_Project`, and run `MasterScript.R` to execute the entire analysis pipeline.\n",
       "\n",
       "---\n",
       "\n",
       "### **Final Notes**\n",
       "\n",
       "- **Dependencies:** Ensure that all necessary packages are installed and up-to-date before running the scripts.\n",
       "\n",
       "- **Data Files:** Replace placeholder filenames like `your_dataset.csv` and `pollination_network.csv` with the actual paths to your data files.\n",
       "\n",
       "- **Customization:** Review and modify the scripts as needed to better fit the specific nuances of your data and research questions.\n",
       "\n",
       "- **Error Handling:** Monitor the console for any warnings or errors during script execution and address them accordingly.\n",
       "\n",
       "By following this structured approach, you can efficiently perform comprehensive analyses on the impacts of beekeeping on wild bee diversity and pollination networks, culminating in a well-documented report of your findings."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, Markdown\n",
    "# display(HTML(executed_plan_steps.content))\n",
    "display(Markdown(executed_plan_steps.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refine each step and run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
