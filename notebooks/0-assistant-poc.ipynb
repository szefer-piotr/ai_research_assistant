{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "# If you want to chunk PDF text, you can also import TextSplitter utilities:\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import PyPDF2\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configure OpenAI Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY= os.getenv('OPENAI_API_KEY')\n",
    "# In code, you might do:\n",
    "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract all text from a PDF file using PyPDF2.\n",
    "    \"\"\"\n",
    "    text_content = []\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        for page in reader.pages:\n",
    "            text_content.append(page.extract_text())\n",
    "    return \"\\n\".join(text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def summarize_excel_to_json(file_path):\n",
    "    \"\"\"\n",
    "    Reads an Excel (.xlsx) file and creates a JSON summary of each sheet.\n",
    "    For each column it provides:\n",
    "      1. The variable (column) name.\n",
    "      2. The inferred variable type (numeric, datetime, categorical).\n",
    "      3. For numeric columns: standard summary statistics.\n",
    "      4. For categorical columns: unique values and their counts.\n",
    "      5. For datetime columns: the time span (min and max dates).\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): The path to the Excel file.\n",
    "\n",
    "    Returns:\n",
    "        str: A JSON string summarizing the workbook.\n",
    "    \"\"\"\n",
    "    workbook_summary = {}\n",
    "    # Load the Excel file\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "\n",
    "    # Process each sheet in the workbook\n",
    "    for sheet in xls.sheet_names:\n",
    "        df = pd.read_excel(xls, sheet_name=sheet)\n",
    "        sheet_summary = []\n",
    "        \n",
    "        # Process each column in the sheet\n",
    "        for col in df.columns:\n",
    "            column_summary = {\"variable_name\": str(col)}\n",
    "            series = df[col]\n",
    "\n",
    "            # Infer the variable type: numeric, datetime, or categorical\n",
    "            if pd.api.types.is_numeric_dtype(series):\n",
    "                column_summary[\"variable_type\"] = \"numeric\"\n",
    "                # Compute summary statistics\n",
    "                stats = series.describe()\n",
    "                column_summary[\"summary_statistics\"] = {\n",
    "                    \"count\": stats.get(\"count\"),\n",
    "                    \"mean\": stats.get(\"mean\"),\n",
    "                    \"std\": stats.get(\"std\"),\n",
    "                    \"min\": stats.get(\"min\"),\n",
    "                    \"25%\": stats.get(\"25%\"),\n",
    "                    \"50%\": stats.get(\"50%\"),\n",
    "                    \"75%\": stats.get(\"75%\"),\n",
    "                    \"max\": stats.get(\"max\")\n",
    "                }\n",
    "            elif pd.api.types.is_datetime64_any_dtype(series):\n",
    "                column_summary[\"variable_type\"] = \"datetime\"\n",
    "                # Compute time span (min and max)\n",
    "                times = series.dropna()\n",
    "                if not times.empty:\n",
    "                    column_summary[\"time_span\"] = {\n",
    "                        \"start\": str(times.min()),\n",
    "                        \"end\": str(times.max())\n",
    "                    }\n",
    "                else:\n",
    "                    column_summary[\"time_span\"] = {\"start\": None, \"end\": None}\n",
    "            else:\n",
    "                column_summary[\"variable_type\"] = \"categorical\"\n",
    "                # Compute unique values and their counts\n",
    "                uniques = series.value_counts(dropna=False)\n",
    "                unique_values = []\n",
    "                for value, count in uniques.items():\n",
    "                    # Represent NaN values as the string \"NaN\"\n",
    "                    value_str = \"NaN\" if pd.isna(value) else str(value)\n",
    "                    unique_values.append({\"value\": value_str, \"count\": int(count)})\n",
    "                column_summary[\"unique_values\"] = unique_values\n",
    "\n",
    "            sheet_summary.append(column_summary)\n",
    "        workbook_summary[sheet] = sheet_summary\n",
    "\n",
    "    # Convert the dictionary to a formatted JSON string\n",
    "    json_str = json.dumps(workbook_summary, indent=2)\n",
    "    return json_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsx_path = \"../data/poc_example_data/lazaro_et_al_2021.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_summary = summarize_excel_to_json(xlsx_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LangChain LLM Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization_llm = ChatOpenAI(\n",
    "    temperature=0.0,\n",
    "    model_name=\"gpt-4o\" \n",
    ")\n",
    "\n",
    "planner_llm = ChatOpenAI(\n",
    "    temperature=1,\n",
    "    model_name=\"o1-mini\"\n",
    ")\n",
    "\n",
    "executor_llm = ChatOpenAI(\n",
    "    temperature=0.0,\n",
    "    model_name=\"o1-mini\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_summary_prompt = PromptTemplate(\n",
    "    input_variables=[\"full_text\"],\n",
    "    template=(\n",
    "        \"You are a model specialized in ecological data analysis.\\n\"\n",
    "        \"Read the following text delimited by triple backticks and list all information on the dataset and statistical analyses used.\\n\"\n",
    "        \"Focus ONLY on:\\n\"\n",
    "        \"- Extracting all of the tested hypotheses.\\n\"\n",
    "        \"- Listing all variables that were collected.\\n\"\n",
    "        \"- Providing example values for categorical variables, and ranges for continuous variables (if available).\\n\"\n",
    "        \"- Listing all statistical methods with every detail of the performed analysis (specifically which functions, settings, and variables were used).\\n\"\n",
    "        \"Return only the report.\\n\"\n",
    "        \"```\\n{full_text}\\n```\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "planner_prompt = PromptTemplate(\n",
    "    input_variables=[\"methodology_summary\", \"dataset_summary\"],\n",
    "    template=(\n",
    "        \"You are a planning model. Based on the methodology summary and dataset summary, \"\n",
    "        \"plan a step-by-step routine (as programmatic pseudocode or structured steps) \"\n",
    "        \"to execute the identified statistical analyses on the full dataset.\\n\"\n",
    "        \"Think how each analysis helps to answer indyvidual hypotheses.\\n\\n\"\n",
    "        \"Methodology Summary:\\n{methodology_summary}\\n\\n\"\n",
    "        \"Dataset Summary:\\n{dataset_summary}\\n\\n\"\n",
    "        \"Provide your plan in XML format, with each <Step> containing a structured explanation \"\n",
    "        \"of how to implement it programmatically, and which hypothesis it addresses.\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "executor_prompt = PromptTemplate(\n",
    "    input_variables=[\"analysis_plan_xml\"],\n",
    "    template=(\n",
    "        \"You are an executor model specialized in generating R scripts for each step. \"\n",
    "        \"Given the plan in XML, do the following:\\n\"\n",
    "        \"1. Generate separate R scripts for each analysis step.\\n\"\n",
    "        \"1.1. Use variable names from the data summary.\\n\"\n",
    "        \"1.2. Check whether an analysis is suitable for the variable types.\\n\"\n",
    "        \"1.3. Provide suggestions in comments on alternativees analyses.\\n\"\n",
    "        \"2. Generate a single master R script that runs them all in a structured manner.\\n\"\n",
    "        \"Output your results clearly, indicating how the scripts should be saved.\\n\\n\"\n",
    "        \"Plan XML:\\n{analysis_plan_xml}.\\n\"\n",
    "        \"Dataset summary:: \\n{dataset_summary}.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Read PDF and extract methodology ---\n",
    "pdf_path = \"../data/poc_example_data/lazaro_et_al_2021_accessible.pdf\"\n",
    "full_text = extract_text_from_pdf(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = methods_summary_prompt | summarization_llm\n",
    "methods_summary_result = chain.invoke({\"full_text\": full_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plan statistical analyses based on the methodology summary and the dataset summary\n",
    "planner_chain = planner_prompt | planner_llm\n",
    "plan_analyses_xml = planner_chain.invoke({\n",
    "    \"methodology_summary\": methods_summary_result,\n",
    "    \"dataset_summary\": dataset_summary\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='```xml\\n<AnalysisPlan>\\n    <Step number=\"1\">\\n        <Description>Load Required Libraries</Description>\\n        <Details>\\n            <Instruction>Ensure all necessary R packages are installed and loaded. This includes packages for statistical modeling, data manipulation, and network analysis.</Instruction>\\n            <Code>\\n                <![CDATA[\\n                # Install packages if not already installed\\n                required_packages <- c(\"lme4\", \"MuMIn\", \"car\", \"r2glmm\", \"piecewiseSEM\", \\n                                       \"bipartite\", \"dplyr\", \"tidyr\", \"emmeans\", \"corrr\")\\n                installed_packages <- rownames(installed.packages())\\n                for(pkg in required_packages){\\n                    if(!pkg %in% installed_packages){\\n                        install.packages(pkg)\\n                    }\\n                }\\n\\n                # Load libraries\\n                library(lme4)\\n                library(MuMIn)\\n                library(car)\\n                library(r2glmm)\\n                library(piecewiseSEM)\\n                library(bipartite)\\n                library(dplyr)\\n                library(tidyr)\\n                library(emmeans)\\n                library(corrr)\\n                ]]>\\n            </Code>\\n        </Details>\\n    </Step>\\n\\n    <Step number=\"2\">\\n        <Description>Import and Inspect Dataset</Description>\\n        <Details>\\n            <Instruction>Load the dataset into R and perform initial inspections to understand its structure and identify any missing or inconsistent data.</Instruction>\\n            <Code>\\n                <![CDATA[\\n                # Replace \\'your_dataset.csv\\' with the actual file name and path\\n                wild_bee_data <- read.csv(\"your_dataset.csv\", stringsAsFactors = TRUE)\\n\\n                # View the first few rows\\n                head(wild_bee_data)\\n\\n                # Summary statistics\\n                summary(wild_bee_data)\\n\\n                # Check for missing values\\n                sapply(wild_bee_data, function(x) sum(is.na(x)))\\n                ]]>\\n            </Code>\\n        </Details>\\n    </Step>\\n\\n    <Step number=\"3\">\\n        <Description>Data Preprocessing</Description>\\n        <Details>\\n            <Instruction>\\n                Prepare the data for analysis by handling missing values, encoding categorical variables, and scaling numerical variables as required.\\n            </Instruction>\\n            <SubSteps>\\n                <SubStep>\\n                    <Description>Handle Missing Values</Description>\\n                    <Details>\\n                        <Instruction>Decide on a strategy to handle missing data, such as imputation or removal of incomplete cases.</Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Example: Remove rows with missing values\\n                            wild_bee_data <- na.omit(wild_bee_data)\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Encode Categorical Variables</Description>\\n                    <Details>\\n                        <Instruction>Ensure that categorical variables are properly encoded as factors.</Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Convert categorical variables to factors\\n                            categorical_vars <- c(\"Island\", \"Island_Site\", \"family\", \"InsectSpecies\", \\n                                                  \"Apis\")\\n                            wild_bee_data[categorical_vars] <- lapply(wild_bee_data[categorical_vars], as.factor)\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Scale Numerical Variables</Description>\\n                    <Details>\\n                        <Instruction>Scale numerical variables as needed, especially for models that are sensitive to variable scaling.</Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Example: Scale numerical predictors\\n                            numeric_vars <- c(\"NumberHivesMinistry2005_2015\", \"HiveDensityMinistry2005-2015\",\\n                                              \"HiveDensityMinistry_STUDYYEAR\", \"NumberApis\", \"FlowerAbundance\",\\n                                              \"FlowerRichness\", \"LandscapeHeterogeneity\", \"Areakm2\",\\n                                              \"%NaturalHabitats\")\\n                            wild_bee_data[numeric_vars] <- scale(wild_bee_data[numeric_vars])\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n            </SubSteps>\\n        </Details>\\n    </Step>\\n\\n    <Step number=\"4\">\\n        <Description>Generalized Linear Mixed Models (GLMMs)</Description>\\n        <Details>\\n            <Instruction>Analyze the relationship between honey bee visitation rate and wild bee abundance and richness using GLMMs.</Instruction>\\n            <SubSteps>\\n                <SubStep>\\n                    <Description>Model Wild Bee Abundance</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Fit a GLMM for wild bee abundance with honey bee visitation rate and other predictors. Include \\'Island\\' as a random effect and use a Gamma distribution with a log link function.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Wild Bee Abundance Model\\n                            abundance_model <- glmer(WildBeeAbundanceSt ~ NumberApis + FlowerAbundance + FlowerRichness + \\n                                                     LandscapeHeterogeneity + log(Areakm2) + \\n                                                     (1 | Island), \\n                                                     data = wild_bee_data, \\n                                                     family = Gamma(link = \"log\"))\\n                            summary(abundance_model)\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Model Wild Bee Richness</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Fit a GLMM for wild bee richness using the same predictors and random effect as above.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Wild Bee Richness Model\\n                            richness_model <- glmer(WildBeeRichnessSt ~ NumberApis + FlowerAbundance + FlowerRichness + \\n                                                    LandscapeHeterogeneity + log(Areakm2) + \\n                                                    (1 | Island), \\n                                                    data = wild_bee_data, \\n                                                    family = Gamma(link = \"log\"))\\n                            summary(richness_model)\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Model Selection with Dredge</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Perform model selection using the dredge function to identify the best models with up to 4 predictors.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Set global options for MuMIn\\n                            options(na.action = \"na.fail\")\\n\\n                            # Model selection for abundance\\n                            abundance_dredge <- dredge(abundance_model, m.lim = c(0,4))\\n                            print(abundance_dredge)\\n\\n                            # Select the best model\\n                            best_abundance_model <- get.models(abundance_dredge, subset = 1)[[1]]\\n                            summary(best_abundance_model)\\n\\n                            # Model selection for richness\\n                            richness_dredge <- dredge(richness_model, m.lim = c(0,4))\\n                            print(richness_dredge)\\n\\n                            # Select the best model\\n                            best_richness_model <- get.models(richness_dredge, subset = 1)[[1]]\\n                            summary(best_richness_model)\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Assess Model Significance and R²</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Use likelihood ratio tests and calculate R² values to assess model performance.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Likelihood Ratio Tests\\n                            Anova(best_abundance_model, test = \"LRT\")\\n                            Anova(best_richness_model, test = \"LRT\")\\n\\n                            # Calculate R²\\n                            r2beta(best_abundance_model, method = \"nsjmin\", partial = TRUE)\\n                            r2beta(best_richness_model, method = \"nsjmin\", partial = TRUE)\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n            </SubSteps>\\n        </Details>\\n    </Step>\\n\\n    <Step number=\"5\">\\n        <Description>Variation Inflation Factor (VIF) Analysis</Description>\\n        <Details>\\n            <Instruction>Identify and address multicollinearity among landscape variables using VIF.</Instruction>\\n            <Code>\\n                <![CDATA[\\n                # Calculate VIF for the best abundance model\\n                vif(best_abundance_model)\\n\\n                # Calculate VIF for the best richness model\\n                vif(best_richness_model)\\n\\n                # If VIF > 5 or 10, consider removing or combining variables\\n                ]]>\\n            </Code>\\n        </Details>\\n    </Step>\\n\\n    <Step number=\"6\">\\n        <Description>Piecewise Structural Equation Modeling (SEM)</Description>\\n        <Details>\\n            <Instruction>\\n                Summarize direct and indirect effects of honey bee visitation rate on wild bee network metrics using Piecewise SEM.\\n            </Instruction>\\n            <SubSteps>\\n                <SubStep>\\n                    <Description>Scale Variables</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Scale the necessary variables before fitting the SEM.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            wild_bee_data_scaled <- wild_bee_data %>%\\n                                mutate_at(vars(NumberApis, FlowerAbundance, FlowerRichness, \\n                                               LandscapeHeterogeneity, Areakm2, \\n                                               WildBeeAbundanceSt, WildBeeRichnessSt), scale)\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Define SEM Model</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Specify the relationships between variables as per the hypotheses.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            sem_model <- psem(\\n                                glmer(WildBeeAbundanceSt ~ NumberApis + FlowerAbundance + FlowerRichness + \\n                                      LandscapeHeterogeneity + log(Areakm2) + \\n                                      (1 | Island), \\n                                      data = wild_bee_data_scaled, \\n                                      family = Gamma(link = \"log\")),\\n                                glmer(WildBeeRichnessSt ~ NumberApis + FlowerAbundance + FlowerRichness + \\n                                      LandscapeHeterogeneity + log(Areakm2) + \\n                                      (1 | Island), \\n                                      data = wild_bee_data_scaled, \\n                                      family = Gamma(link = \"log\")),\\n                                log(Areakm2) ~ NumberApis + FlowerAbundance + \\n                                    FlowerRichness + LandscapeHeterogeneity,\\n                                NumberApis ~ FlowerAbundance + FlowerRichness + LandscapeHeterogeneity\\n                            )\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Fit SEM Model and Assess Fit</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Fit the SEM model and evaluate its goodness-of-fit using directed separation tests.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Fit the SEM model\\n                            sem_fit <- sem.fit(sem_model, data = wild_bee_data_scaled)\\n                            summary(sem_fit, standardize = TRUE, fit.measures = TRUE)\\n\\n                            # Goodness-of-fit tests\\n                            sem.fit(sem_model, data = wild_bee_data_scaled, test = \"standard\")\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n            </SubSteps>\\n        </Details>\\n    </Step>\\n\\n    <Step number=\"7\">\\n        <Description>Pollination Network Analysis</Description>\\n        <Details>\\n            <Instruction>\\n                Construct and analyze pollination networks using the bipartite package.\\n            </Instruction>\\n            <SubSteps>\\n                <SubStep>\\n                    <Description>Construct Bipartite Networks</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Use hand-netting data to create bipartite matrices representing plant-pollinator interactions.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Assuming \\'pollination_data\\' is a separate dataframe with Plant and Pollinator interactions\\n                            # Replace with actual data loading if different\\n                            pollination_data <- read.csv(\"pollination_network.csv\", stringsAsFactors = TRUE)\\n\\n                            # Create a bipartite matrix\\n                            bipartite_matrix <- with(pollination_data, table(PlantSpecies, PollinatorSpecies))\\n\\n                            # Convert to matrix\\n                            bipartite_matrix <- as.matrix(bipartite_matrix)\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Calculate Network Indices</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Calculate various network metrics such as number of links, linkage density, nestedness, and modularity.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Number of links\\n                            num_links <- networklevel(bipartite_matrix, index = \"links\")\\n\\n                            # Number of plant species\\n                            num_plants <- networklevel(bipartite_matrix, index = \"species.level\")\\n\\n                            # Linkage density\\n                            linkage_density <- linkage(bipartite_matrix)\\n\\n                            # Nestedness\\n                            nestedness <- networklevel(bipartite_matrix, index = \"weighted NODF\")\\n\\n                            # Modularity\\n                            modularity <- networklevel(bipartite_matrix, index = \"module\")\\n\\n                            # Combine indices into a dataframe\\n                            network_indices <- data.frame(\\n                                NumberOfLinks = num_links,\\n                                NumberOfPlantSpecies = num_plants,\\n                                LinkageDensity = linkage_density,\\n                                Nestedness = nestedness,\\n                                Modularity = modularity\\n                            )\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Assess Against Null Models</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Compare observed network metrics against null models using the vaznull null model for z-scores.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Calculate z-scores using vaznull null model\\n                            z_linkage_density <- nullmodel(bipartite_matrix, method = \"vaznull\")$zLinkage\\n                            z_nestedness <- nullmodel(bipartite_matrix, method = \"vaznull\")$zNODF\\n                            z_modularity <- nullmodel(bipartite_matrix, method = \"vaznull\")$zModularity\\n\\n                            # Add z-scores to network_indices\\n                            network_indices$Z_LinkageDensity <- z_linkage_density\\n                            network_indices$Z_Nestedness <- z_nestedness\\n                            network_indices$Z_Modularity <- z_modularity\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n            </SubSteps>\\n        </Details>\\n    </Step>\\n\\n    <Step number=\"8\">\\n        <Description>Potential Competition Analysis</Description>\\n        <Details>\\n            <Instruction>\\n                Measure species niche overlap using the Apparent Competition Index as per Müller et al. (1999).\\n            </Instruction>\\n            <SubSteps>\\n                <SubStep>\\n                    <Description>Prepare Species Interaction Matrix</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Transpose the species interaction matrix to align species appropriately for PAC calculation.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Transpose the bipartite matrix\\n                            transposed_matrix <- t(bipartite_matrix)\\n\\n                            # Ensure the matrix is binary (presence/absence)\\n                            transposed_matrix[transposed_matrix > 0] <- 1\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Calculate Apparent Competition Index</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Use the PAC function to compute the niche overlap among species.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Using PAC function (assuming PAC is defined or use a suitable package)\\n                            # If PAC function is not available, consider using niche overlap functions from other packages\\n\\n                            # Example using nicheOverlap from vegan\\n                            if(!\"vegan\" %in% installed.packages()){\\n                                install.packages(\"vegan\")\\n                            }\\n                            library(vegan)\\n\\n                            # Calculate niche overlap using Pianka\\'s index\\n                            niche_overlap <- nicheOverlap(transposed_matrix, method = \"Pianka\")\\n\\n                            # Convert to Apparent Competition Index if specific formula is needed\\n                            # Placeholder as PAC formula is specific\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n            </SubSteps>\\n        </Details>\\n    </Step>\\n\\n    <Step number=\"9\">\\n        <Description>A Posteriori Tests for Differences Between Slopes</Description>\\n        <Details>\\n            <Instruction>\\n                Perform post-hoc tests to examine differences between slopes for each wild bee family using the emtrends function from the emmeans package.\\n            </Instruction>\\n            <SubSteps>\\n                <SubStep>\\n                    <Description>Fit Interaction Models</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Include interaction terms between honey bee visitation rate and bee family in the GLMMs.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Interaction model for abundance\\n                            interaction_model_abundance <- glmer(WildBeeAbundanceSt ~ NumberApis * family + FlowerAbundance + \\n                                                                 FlowerRichness + LandscapeHeterogeneity + log(Areakm2) + \\n                                                                 (1 | Island), \\n                                                                 data = wild_bee_data, \\n                                                                 family = Gamma(link = \"log\"))\\n                            \\n                            # Interaction model for richness\\n                            interaction_model_richness <- glmer(WildBeeRichnessSt ~ NumberApis * family + FlowerAbundance + \\n                                                                FlowerRichness + LandscapeHeterogeneity + log(Areakm2) + \\n                                                                (1 | Island), \\n                                                                data = wild_bee_data, \\n                                                                family = Gamma(link = \"log\"))\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Perform Emtrends Analysis</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Use emtrends to estimate and compare the slopes of honey bee visitation rate across different bee families.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Emtrends for abundance\\n                            emtrends_abundance <- emtrends(interaction_model_abundance, \\n                                                          pairwise ~ family, \\n                                                          var = \"NumberApis\")\\n                            summary(emtrends_abundance)\\n\\n                            # Emtrends for richness\\n                            emtrends_richness <- emtrends(interaction_model_richness, \\n                                                         pairwise ~ family, \\n                                                         var = \"NumberApis\")\\n                            summary(emtrends_richness)\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n            </SubSteps>\\n        </Details>\\n    </Step>\\n\\n    <Step number=\"10\">\\n        <Description>Export and Document Results</Description>\\n        <Details>\\n            <Instruction>\\n                Save all model outputs, summaries, and important statistics to files for reporting and further analysis.\\n            </Instruction>\\n            <SubSteps>\\n                <SubStep>\\n                    <Description>Save Model Summaries</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Export summaries of GLMMs, SEMs, and other analyses to text or PDF files.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Save GLMM summaries\\n                            sink(\"GLMM_Abundance_Summary.txt\")\\n                            summary(best_abundance_model)\\n                            sink()\\n\\n                            sink(\"GLMM_Richness_Summary.txt\")\\n                            summary(best_richness_model)\\n                            sink()\\n\\n                            # Save SEM summary\\n                            sink(\"SEM_Summary.txt\")\\n                            summary(sem_fit, standardize = TRUE, fit.measures = TRUE)\\n                            sink()\\n\\n                            # Save Emtrends summaries\\n                            sink(\"Emtrends_Abundance_Summary.txt\")\\n                            summary(emtrends_abundance)\\n                            sink()\\n\\n                            sink(\"Emtrends_Richness_Summary.txt\")\\n                            summary(emtrends_richness)\\n                            sink()\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Save Network Indices</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Export the calculated network indices to a CSV file for reporting.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            write.csv(network_indices, \"Pollination_Network_Indices.csv\", row.names = FALSE)\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Save PAC Results</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Export the Apparent Competition Index results to a CSV file.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            write.csv(niche_overlap, \"Apparent_Competition_Index.csv\", row.names = TRUE)\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n            </SubSteps>\\n        </Details>\\n    </Step>\\n\\n    <Step number=\"11\">\\n        <Description>Visualization of Results</Description>\\n        <Details>\\n            <Instruction>\\n                Create visualizations to illustrate the findings from the statistical analyses, such as effect plots, network diagrams, and VIF plots.\\n            </Instruction>\\n            <SubSteps>\\n                <SubStep>\\n                    <Description>Effect Plots for GLMMs</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Use the emmeans package to plot estimated marginal means and trends.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Plot for abundance\\n                            plot(emtrends_abundance, comparisons = TRUE) +\\n                                ggtitle(\"Effect of NumberApis on Wild Bee Abundance by Family\")\\n\\n                            # Plot for richness\\n                            plot(emtrends_richness, comparisons = TRUE) +\\n                                ggtitle(\"Effect of NumberApis on Wild Bee Richness by Family\")\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Network Diagrams</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Visualize the pollination networks using the bipartite package.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Basic network plot\\n                            plotweb(bipartite_matrix, method = \"normal\", \\n                                    title = \"Pollination Network\", \\n                                    text.rot = 90, text.spacing = 0.5)\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>VIF Plot</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Visualize VIF values to assess multicollinearity.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Calculate VIF and plot\\n                            vif_values <- vif(best_abundance_model)\\n                            vif_df <- data.frame(Variable = names(vif_values), VIF = vif_values)\\n\\n                            library(ggplot2)\\n                            ggplot(vif_df, aes(x = reorder(Variable, VIF), y = VIF)) +\\n                                geom_bar(stat = \"identity\", fill = \"steelblue\") +\\n                                coord_flip() +\\n                                geom_hline(yintercept = 5, linetype = \"dashed\", color = \"red\") +\\n                                labs(title = \"VIF Values for Predictors\",\\n                                     x = \"Variables\",\\n                                     y = \"VIF\") +\\n                                theme_minimal()\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n            </SubSteps>\\n        </Details>\\n    </Step>\\n\\n    <Step number=\"12\">\\n        <Description>Report Findings</Description>\\n        <Details>\\n            <Instruction>\\n                Compile all results, figures, and interpretations into a comprehensive report detailing the impacts of beekeeping on wild bee diversity and pollination networks.\\n            </Instruction>\\n            <SubSteps>\\n                <SubStep>\\n                    <Description>Create Report Structure</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Organize the report into sections such as Introduction, Methods, Results, Discussion, and Conclusion.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Example using R Markdown\\n                            # Create a new R Markdown file and include necessary sections\\n                            rmarkdown::draft(\"Bee_Analysis_Report.Rmd\", template = \"html_document\", package = \"rmarkdown\")\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Incorporate Results and Figures</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Insert the saved summaries, network indices, PAC results, and visualizations into the respective sections of the report.\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Example R Markdown inclusion\\n                            # In the Rmd file, include code chunks to read and display results\\n                            # ```{r GLMM_Summary}\\n                            # readLines(\"GLMM_Abundance_Summary.txt\")\\n                            # ```\\n                            # \\n                            # ```{r Network_Indices}\\n                            # network_indices <- read.csv(\"Pollination_Network_Indices.csv\")\\n                            # print(network_indices)\\n                            # ```\\n                            # \\n                            # Include plots by referencing the saved plot objects or regenerating them\\n                            # ```{r VIF_Plot, fig.height=6, fig.width=8}\\n                            # print(vif_plot)\\n                            # ```\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n                <SubStep>\\n                    <Description>Finalize and Knit Report</Description>\\n                    <Details>\\n                        <Instruction>\\n                            Review the report for completeness and accuracy, then knit it to the desired format (e.g., PDF, HTML).\\n                        </Instruction>\\n                        <Code>\\n                            <![CDATA[\\n                            # Knit the report\\n                            rmarkdown::render(\"Bee_Analysis_Report.Rmd\")\\n                            ]]>\\n                        </Code>\\n                    </Details>\\n                </SubStep>\\n            </SubSteps>\\n        </Details>\\n    </Step>\\n</AnalysisPlan>\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 5620, 'prompt_tokens': 18218, 'total_tokens': 23838, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o1-mini-2024-09-12', 'system_fingerprint': 'fp_f56e40de61', 'finish_reason': 'stop', 'logprobs': None}, id='run-a320bf73-ceaf-4936-87bb-fe0f9f301d0f-0', usage_metadata={'input_tokens': 18218, 'output_tokens': 5620, 'total_tokens': 23838, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 256}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plan_analyses_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executor_chain = planner_prompt | planner_llm\n",
    "executed_plan_steps = planner_chain.invoke({\n",
    "    \"analysis_plan_xml\": plan_analyses_xml,\n",
    "    \"dataset_summary\": dataset_summmary\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
